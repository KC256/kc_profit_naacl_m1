{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def do_test(train_log_path):\n",
    "    print(os.path.basename(train_log_path))\n",
    "    with open(train_log_path, 'r') as file: #outputパスの取得\n",
    "        lines = file.readlines()\n",
    "        search_strings = [\"output:\", \"INPUT_TEXT:\", \"USING_MODEL:\"]\n",
    "        key_values = []\n",
    "        for i, search_string in enumerate(search_strings):\n",
    "            for line in lines:\n",
    "                if search_string in line:\n",
    "                    temp = line.split(':')\n",
    "                    temp = temp[1].replace(\" \", \"\")\n",
    "                    temp = temp.replace(\"\\n\", \"\")\n",
    "                    key_values.append(temp)\n",
    "                    break\n",
    "            \n",
    "        print(key_values)\n",
    "        resumes_folder_path = os.path.join(\"/home/fukuda/\", key_values[0])\n",
    "        input_text = key_values[1]\n",
    "        using_model = key_values[2]\n",
    "        \n",
    "        if input_text==\"tweetonly\":\n",
    "            test_pickles_folder = \"/home/ubuntu/datasets/pickles_0tumeru/for_test\"\n",
    "            test_pickles = os.listdir(test_pickles_folder)\n",
    "            \n",
    "        if input_text==\"withtimefeatsSEC\":\n",
    "            test_pickles_folder = \"/home/fukuda/datasets/pickles_withSECtimefeature_0tumeru/for_test\"\n",
    "            test_pickles = os.listdir(test_pickles_folder)\n",
    "            \n",
    "        if input_text==\"withSEC\":\n",
    "            test_pickles_folder = \"/home/ubuntu/datasets/pickles_oneSEC_0tumeru/for_test\" #SECが1か２かでここのパスを/home/ubuntu/datasets/pickles_withSEC_0tumeruに変える必要\n",
    "            test_pickles = os.listdir(test_pickles_folder)\n",
    "            \n",
    "        # elif input_text==\"withSEC\":\n",
    "        #     test_pickles = \"/home/ubuntu/datasets/pickles_0tumeru/for_test\"\n",
    "        \n",
    "        # initial_account_balances = [10000, 100000, 1000000, 10000000] #ここでテストしたいinitial_account_balance設定\n",
    "        initial_account_balances = [100000]\n",
    "        i=0\n",
    "        for initial_account_balance in initial_account_balances:\n",
    "            for test_pickle in test_pickles:\n",
    "                try:\n",
    "                    test_pickle = os.path.join(test_pickles_folder, test_pickle)\n",
    "                    # print(test_pickle)\n",
    "                    output_log_folder = \"/home/fukuda/nohup_test_outputs_m2_212\"\n",
    "                    output_log_name = os.path.basename(train_log_path)[:-4] + \":\" + str(initial_account_balance) + \":\" + test_pickle[-36:-15]\n",
    "                    output_log_path = os.path.join(output_log_folder, output_log_name)\n",
    "                    \n",
    "                    # counter = 1\n",
    "                    # while os.path.exists(output_log_path + \".log\"): #すでにファイルが存在している場合通し番号を追加\n",
    "                    #     counter += 1\n",
    "                    #     output_log_path = f\"{output_log_path}:{counter}\"\n",
    "                    \n",
    "                    j=0\n",
    "                    while os.path.exists(output_log_path + \".log\"): #すでにファイルが存在している場合スキップ　上と選択\n",
    "                        print(\"already exist\", output_log_name)\n",
    "                        j=1\n",
    "                        break\n",
    "                        \n",
    "                    output_log_path = output_log_path + \".log\"\n",
    "                    \n",
    "                    if j==0:\n",
    "                        command = f\"setsid nohup python /home/fukuda/kc_profit_naacl/profit_naacl_new_fortest/main_2.py \\\n",
    "                                    --test_pickle={test_pickle} \\\n",
    "                                    --train_pickle={test_pickle} \\\n",
    "                                    --initial_account_balance={initial_account_balance} --mode=test \\\n",
    "                                    --resumes_folder_path={resumes_folder_path} \\\n",
    "                                    > {output_log_path} 2>&1 &\"\n",
    "                        \n",
    "                        # print(\"not exist\")\n",
    "                        print(output_log_name)\n",
    "                        result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, text=True)\n",
    "                        if i%5==4:\n",
    "                                print(\"sleep memory usage:\", psutil.virtual_memory().percent)\n",
    "                                time.sleep(50)\n",
    "                        i+=1\n",
    "                        while True:\n",
    "                            if psutil.virtual_memory().percent > 50: #メモリ使用率が60%以上で\n",
    "                                print(\"msleep memory usage:\", psutil.virtual_memory().percent)\n",
    "                                time.sleep(10)\n",
    "                            else:\n",
    "                                break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(\"error:\", e)\n",
    "                \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_test(\"/home/fukuda/nohup_outputs_m2_212/with2SEC_tf_model4_2.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already exist: with2SEC_tf_model4_2:100000:2015-12-10~2015-12-16.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-15~2015-10-21.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-22~2015-11-22.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-29~2015-11-29.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-08~2015-11-08.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-15~2015-11-15.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-08~2015-10-14.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-22~2015-10-28.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-05~2015-12-05.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-08~2015-11-08.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-01~2015-10-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-19~2015-11-25.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-22~2015-10-28.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-22~2015-10-28.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-12~2015-12-12.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-26~2015-12-02.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-12-03~2015-12-09.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-12~2015-12-12.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-29~2015-11-04.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-12-03~2015-12-09.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-08~2015-11-08.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-12~2015-11-18.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-12~2015-12-12.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-26~2015-12-02.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-12~2015-11-18.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-12~2015-11-18.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-05~2015-12-05.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-12-17~2015-12-23.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-19~2015-11-25.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-05~2015-11-11.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-12-10~2015-12-16.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-15~2015-11-15.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-15~2015-11-15.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-01~2015-10-30.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-29~2015-11-29.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-12-17~2015-12-23.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-26~2015-12-26.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-22~2015-11-22.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-08~2015-10-14.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-26~2015-12-26.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-12-24~2015-12-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-19~2015-12-19.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-26~2015-12-02.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-19~2015-12-19.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-26~2015-12-26.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-01~2015-10-07.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-12~2015-11-18.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-12-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-26~2015-12-02.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-29~2015-11-29.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-15~2015-10-21.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-01~2015-10-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-12-17~2015-12-23.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-15~2015-11-15.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-01~2015-10-07.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-19~2015-12-19.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-01~2015-10-30.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-12-24~2015-12-30.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-05~2015-11-11.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-05~2015-12-05.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-26~2015-12-26.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-08~2015-10-14.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-12-03~2015-12-09.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-19~2015-11-25.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-08~2015-10-14.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-12-10~2015-12-16.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-22~2015-11-22.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-01~2015-10-07.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-05~2015-12-05.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-11-12~2015-12-12.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-12-17~2015-12-23.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-11-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-12-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-12-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-29~2015-11-04.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-29~2015-11-29.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-15~2015-10-21.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-08~2015-11-08.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-01~2015-10-07.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-29~2015-11-04.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-12-03~2015-12-09.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-01~2015-11-30.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-05~2015-11-11.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-11-19~2015-12-19.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-12-24~2015-12-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-22~2015-10-28.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-10-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-19~2015-11-25.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-12-10~2015-12-16.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-12-01~2015-12-31.log\n",
      "already exist: with2SEC_tf_model4_2:100000:2015-10-15~2015-10-21.log\n",
      "already exist: with2SEC_tf_model4_2:10000000:2015-12-24~2015-12-30.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-11-05~2015-11-11.log\n",
      "already exist: with2SEC_tf_model4_2:1000000:2015-10-29~2015-11-04.log\n",
      "already exist: with2SEC_tf_model4_2:10000:2015-10-22~2015-11-22.log\n"
     ]
    }
   ],
   "source": [
    "#testできてないファイルを削除\n",
    "train_log_folder=\"/home/fukuda/nohup_test_outputs_m2_212\"\n",
    "train_log_files = os.listdir(train_log_folder)\n",
    "\n",
    "for train_log_file in train_log_files:\n",
    "    i=0\n",
    "    train_log_path = os.path.join(train_log_folder, train_log_file)\n",
    "    with open(train_log_path, 'r') as file: #outputパスの取得\n",
    "        lines = file.readlines()\n",
    "        search_string = \"all finish\"\n",
    "        for line in reversed(lines):\n",
    "            if search_string in line:\n",
    "                print(\"already exist:\", train_log_file)\n",
    "                i=1\n",
    "                break\n",
    "            \n",
    "        if i==0:\n",
    "            try:\n",
    "                # os.remove(train_log_path)\n",
    "                print(f\"File {train_log_path} successfully deleted.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred:{train_log_path}: {e}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Profit-naacl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
