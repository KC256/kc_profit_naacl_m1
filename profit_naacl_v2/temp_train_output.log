nohup: 入力を無視します
/home/fukuda/miniconda3/envs/Profit-naacl/lib/python3.9/site-packages/pyfolio/pos.py:26: UserWarning: Module "zipline.assets" not found; mutltipliers will not be applied to position notionals.
  warnings.warn(
start time: 2024-11-06 19:28:08.144662
INPUT_TEXT: tweetonly
USING_MODEL: model_2
output is not made
train_pickle:  ../../datasets/pickles_0tumeru/S_test_data_sorted_in_jsons_6_2015-10-01~2015-10-03_20_7_5_384.pkl
test_pickle:  ../../datasets/pickles_0tumeru/S_test_data_sorted_in_jsons_6_2015-10-01~2015-10-03_20_7_5_384.pkl
args.validate_steps: 25
args.epsilon: 50000
HMAX_NORMALIZE: 10
SELECT_ACTION: default
TRANSACTION_FEE_PERCENT 0.000495
args.train_iter: 200000
args.seed: -1
args.bsize: 1
{'mode': 'train', 'env': 'Humanoid-v2', 'hidden1': 400, 'hidden2': 300, 'rate': 0.001, 'prate': 0.0001, 'warmup': 1, 'discount': 0.99, 'bsize': 1, 'rmsize': 25, 'window_length': 1, 'tau': 0.001, 'ou_theta': 0.15, 'ou_sigma': 0.2, 'ou_mu': 0.0, 'validate_episodes': 1, 'max_episode_length': 500, 'validate_steps': 25, 'output': 'output', 'debug': False, 'init_w': 0.003, 'train_iter': 200000, 'epsilon': 50000, 'seed': -1, 'resume': 'default', 'model': 'time', 'diff': None, 'test_pickle': '../../datasets/pickles_0tumeru/S_test_data_sorted_in_jsons_6_2015-10-01~2015-10-03_20_7_5_384.pkl', 'train_pickle': '../../datasets/pickles_0tumeru/S_test_data_sorted_in_jsons_6_2015-10-01~2015-10-03_20_7_5_384.pkl', 'initial_account_balance': '100000', 'resumes_folder_path': None}
MEMO:
          
  0%|          | 0/200000 [00:00<?, ?it/s]  0%|          | 1/200000 [00:00<15:33:31,  3.57it/s]  0%|          | 2/200000 [00:00<12:23:45,  4.48it/s]args.warmup  1

step: 0
day: 0 train
actions: [ 1.41213858 -9.41015437 -5.4044547   6.96770256  8.13476752 -6.84894018
  8.1450953  -0.19112426 -0.16220721 -7.73892577 -4.21069186 -6.34380663
  5.79401352 -6.60943422  0.60154132  9.05927287 -6.86784633  1.76804224
 -7.95698101  2.9024035 ]
argsort_actions: [ 1 18  9 16  5 13 11  2 10  7  8 14  0 17 19 12  3  4  6 15]
sell index:[ 1 18  9 16  5 13 11  2 10  7  8]  buy index:[15  6  4  3 12 19 17  0 14] 
self.sell_num, self.buy_num, self.hold_num: 0 9 11
self.state[HOLDING_IDX~EMB_IDX]: [1.4121385823128607, 0, 0, 6.967702557370887, 8.134767524368986, 0, 8.145095296907476, 0, 0, 0, 0, 0, 5.79401351669757, 0, 0.6015413244227386, 9.05927287236258, 0, 1.7680422390531159, 0, 2.902403498575261]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [1.41213858 0.         0.         6.96770256 8.13476752 0.
 8.1450953  0.         0.         0.         0.         0.
 5.79401352 0.         0.60154132 9.05927287 0.         1.76804224
 0.         2.9024035 ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio [0.9587425958470162, 0.000738129249402683, 0.0, 0.0, 0.008557530090116864, 0.014786869231849928, 0.0, 0.005210528920801941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00540272780891677, 0.0, 0.00017775727487082948, 0.002740621448984843, 0.0, 0.0016420822548311148, 0.0, 0.00200115787320897]
y_w: [0.9587425958470162, 0.000738129249402683, 0.0, 0.0, 0.008557530090116864, 0.014786869231849928, 0.0, 0.005210528920801941, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00540272780891677, 0.0, 0.00017775727487082948, 0.002740621448984843, 0.0, 0.0016420822548311148, 0.0, 0.00200115787320897]
sum(y_w): 1.0
end_total_asset [  73.81141753    0.            0.          855.73553283 1478.65672544
    0.          521.04225114    0.            0.            0.
    0.            0.          540.26174744    0.           17.77536447
  274.056548      0.          164.20487202    0.          200.11170056]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.args.diff: None
self.reward: -0.00020421997989324156
sum end_total_asset(stocks): 4125.656159435929
self.state[0](cash): 95872.30164076514
today cost: 2.0421997989207847
step_end: 1

step: 1
day: 1 train
actions: [ 8.76347183  8.04014314 -9.9293738  -4.8657804  -1.07974411 -1.47045593
  8.27321013  9.17504603 -9.1284017   4.93626869  4.26271005  5.29815552
  5.84871213  9.82073424  1.56474823 -0.58021722 -7.27605789  5.37180704
  7.78057657  3.93364531]
argsort_actions: [ 2  8 16  3  5  4 15 14 19 10  9 11 17 12 18  1  6  0  7 13]
sell index:[ 2  8 16  3  5  4 15]  buy index:[13  7  0  6  1 18 12 17 11  9 10 19 14] 
self.sell_num, self.buy_num, self.hold_num: 3 13 4
self.state[HOLDING_IDX~EMB_IDX]: [10.175610407471595, 8.040143141302288, 0, 2.1019221565282864, 7.055023411575579, 0, 16.418305427651546, 9.175046034744277, 0, 4.936268685129521, 4.2627100458951155, 5.298155523291124, 11.64272564527488, 9.82073423761868, 2.166289554969494, 8.479055655722181, 0, 7.139849275974447, 7.780576567452457, 6.836048812234308]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [ 8.76347183  8.04014314  0.         -4.8657804  -1.07974411  0.
  8.27321013  9.17504603  0.          4.93626869  4.26271005  5.29815552
  5.84871213  9.82073424  1.56474823 -0.58021722  0.          5.37180704
  7.78057657  3.93364531]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8976190049915773, 0.005333496906833217, 0.010871178057584708, 0.0, 0.0026188937146228814, 0.01291507000790451, 0.0, 0.010661959371420615, 0.012263832586242963, 0.0, 0.0014156464554844711, 0.0016262959800046495, 0.004800387851737773, 0.01096257279289842, 0.008734160366989492, 0.0006647787631427027, 0.0025985550131852725, 0.0, 0.006682020313647559, 0.005405133072574949, 0.004827013754148446]
y_w: [0.8976190049915773, 0.0053505977101854195, 0.011044832132064746, 0.0, 0.002657994377181984, 0.01301241049833812, 0.0, 0.01082813960587266, 0.012348151506924653, 0.0, 0.0014397123616270264, 0.0016504043851083704, 0.004871285613241644, 0.011074662597337519, 0.008763011082609087, 0.0006906684598446699, 0.0026336278452292303, 0.0, 0.006736247555318181, 0.005457647986778729, 0.004945635735908626]
sum(y_w): 1.001124034445148
end_total_asset [ 533.57681414 1087.58074772    0.          262.00089533 1292.05698054
    0.         1066.64996966 1226.90550586    0.          141.62492992
  162.69885274  480.24320653 1096.72411323  873.78797517   66.50618548
  259.96615907    0.          668.4865808   540.74348129  482.90693062]
begin_total_asset [  74.04807925    0.            0.          868.51185365 1489.80131628
    0.          529.16335913    0.            0.            0.
    0.            0.          545.78580049    0.           18.46762304
  277.75550347    0.          165.5374596     0.          205.02936761]
self.daybefore_end_total_asset [  73.81141753    0.            0.          855.73553283 1478.65672544
    0.          521.04225114    0.            0.            0.
    0.            0.          540.26174744    0.           17.77536447
  274.056548      0.          164.20487202    0.          200.11170056]
self.args.diff: None
self.reward: 0.004462654120325169
sum end_total_asset(stocks): 10242.459328087014
self.state[0](cash): 89800.1250133173
today cost: 3.6471293988486853
step_end: 2

step: 2
step == args.warmup+1
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2646, -0.0531,  0.8726, -0.4307, -0.2218, -1.4205, -1.3765,  0.7700,
         -0.0600,  0.5700,  0.7512,  1.9847,  1.5195, -1.4646, -0.7221,  0.4202,
         -0.7818, -0.1568, -1.0516, -0.4134]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.264636   -0.0530598   0.87256074 -0.43071765 -0.22176847 -1.4205102
 -1.3765066   0.76995707 -0.05997138  0.5700499   0.7511689   1.9846958
  1.5195167  -1.4646306  -0.72212327  0.4202129  -0.78178513 -0.15679766
 -1.0515602  -0.4133671 ] <class 'numpy.ndarray'>
action2: [ 1.2631158  -0.03922313  0.8782512  -0.4222448  -0.17862476 -1.4229966
 -1.371294    0.7213779  -0.07437613  0.56125957  0.76010746  1.9903504
  1.5389671  -1.4725451  -0.7246846   0.4156678  -0.7823858  -0.14688483
 -1.0106342  -0.41022572]
action3: [ 1.         -0.03922313  0.8782512  -0.4222448  -0.17862476 -1.
 -1.          0.7213779  -0.07437613  0.56125957  0.76010746  1.
  1.         -1.         -0.7246846   0.4156678  -0.7823858  -0.14688483
 -1.         -0.41022572]
day: 2 train
Reached the end.
self.asset_memory: [100000, 99997.95780020107, 100042.58434140432]
previous_total_asset:100000
end_total_asset:100042.58434140432
total_reward:42.584341404319275
total_cost:  5.68932919776947
total trades:  25
size: 1
next_state_batch [[9.58723016e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
  0%|          | 3/200000 [00:03<87:48:54,  1.58s/it]  0%|          | 4/200000 [00:06<114:05:12,  2.05s/it]to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2644, -0.0537,  0.8723, -0.4307, -0.2219, -1.4208, -1.3768,  0.7701,
         -0.0601,  0.5702,  0.7510,  1.9844,  1.5198, -1.4649, -0.7221,  0.4204,
         -0.7817, -0.1559, -1.0510, -0.4131]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-22.4944]], device='cuda:0')
value_loss: tensor(1.1230, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2644, -0.0543,  0.8723, -0.4307, -0.2218, -1.4212, -1.3772,  0.7697,
         -0.0600,  0.5705,  0.7509,  1.9841,  1.5200, -1.4651, -0.7220,  0.4206,
         -0.7816, -0.1553, -1.0504, -0.4130]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[-40.6275]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(-40.6275, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 3
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2925, -0.0289,  0.8374, -0.4209, -0.2034, -1.4483, -1.3508,  0.7411,
         -0.0393,  0.5885,  0.7751,  2.0046,  1.4959, -1.4451, -0.7040,  0.3841,
         -0.7566, -0.1837, -1.0950, -0.4431]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.2924814  -0.02893094  0.83738464 -0.4208607  -0.20344512 -1.448286
 -1.3507876   0.74111044 -0.03931945  0.5884829   0.77513945  2.0045743
  1.4958526  -1.4450758  -0.7040102   0.3840766  -0.75663006 -0.1837099
 -1.0949923  -0.4430542 ] <class 'numpy.ndarray'>
action2: [ 1.321737   -0.03205033  0.8293321  -0.44672552 -0.17990051 -1.4800348
 -1.3234913   0.68907434 -0.05837208  0.5746978   0.79206854  1.9952707
  1.4927872  -1.4792657  -0.70986557  0.36109975 -0.77961165 -0.14862773
 -1.0153095  -0.4420034 ]
action3: [ 1.         -0.03205033  0.8293321  -0.44672552 -0.17990051 -1.
 -1.          0.68907434 -0.05837208  0.5746978   0.79206854  1.
  1.         -1.         -0.70986557  0.36109975 -0.77961165 -0.14862773
 -1.         -0.4420034 ]

step: 3
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2923, -0.0301,  0.8373, -0.4208, -0.2034, -1.4490, -1.3515,  0.7410,
         -0.0394,  0.5889,  0.7749,  2.0040,  1.4963, -1.4455, -0.7039,  0.3845,
         -0.7565, -0.1822, -1.0939, -0.4427]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.2922609  -0.03014118  0.83727616 -0.42079306 -0.20341435 -1.4490347
 -1.3515048   0.74099106 -0.03943048  0.5889179   0.7748763   2.003955
  1.4962711  -1.4455415  -0.7039034   0.38445053 -0.7564985  -0.18219897
 -1.0938752  -0.44266284] <class 'numpy.ndarray'>
action2: [ 1.2940482  -0.02692189  0.8321743  -0.423206   -0.22129038 -1.4515281
 -1.3685755   0.7414088  -0.00832296  0.5868654   0.7353358   2.0121956
  1.4878834  -1.4486902  -0.66985095  0.3917593  -0.7710394  -0.20499805
 -1.0410659  -0.44063747]
action3: [ 1.         -0.02692189  0.8321743  -0.423206   -0.22129038 -1.
 -1.          0.7414088  -0.00832296  0.5868654   0.7353358   1.
  1.         -1.         -0.66985095  0.3917593  -0.7710394  -0.20499805
 -1.         -0.44063747]
day: 0 train
actions: [ 10.          -0.26921895   8.321743    -4.23206     -2.2129037
 -10.         -10.           7.4140882   -0.08322961   5.8686543
   7.3533583   10.          10.         -10.          -6.698509
   3.917593    -7.7103944   -2.0499804  -10.          -4.406375  ]
argsort_actions: [ 5  6 18 13 16 14 19  3  4 17  1  8 15  9 10  7  2 11 12  0]
sell index:[ 5  6 18 13 16 14 19  3  4 17  1  8]  buy index:[ 0 12 11  2  7 10  9 15] 
self.sell_num, self.buy_num, self.hold_num: 0 8 12
self.state[HOLDING_IDX~EMB_IDX]: [10.0, 0, 8.32174301147461, 0, 0, 0, 0, 7.414088249206543, 0, 5.868654251098633, 7.353358268737793, 10.0, 10.0, 0, 0, 3.917593002319336, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [ -0.17561041  -8.04014314   8.32174301  -2.10192216  -7.05502341
   0.         -16.41830543  -1.76095779   0.           0.93238557
   3.09064822   4.70184448  -1.64272565  -9.82073424  -2.16628955
  -4.56146265   0.          -7.13984928  -7.78057657  -6.83604881]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio [0.9177269053001309, 0.005227137367450917, 0.0, 0.0433347425394471, 0.0, 0.0, 0.0, 0.0, 0.009846968865813408, 0.0, 0.0016556792271503566, 0.002765739868376868, 0.008932786374534981, 0.009324861741225352, 0.0, 0.0, 0.0011851787158701566, 0.0, 0.0, 0.0, 0.0]
y_w: [0.9177269053001309, 0.005227137367450917, 0.0, 0.0433347425394471, 0.0, 0.0, 0.0, 0.0, 0.009846968865813408, 0.0, 0.0016556792271503566, 0.002765739868376868, 0.008932786374534981, 0.009324861741225352, 0.0, 0.0, 0.0011851787158701566, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0000000000000002
end_total_asset [ 522.69245       0.         4333.2977796     0.            0.
    0.            0.          984.65678625    0.          165.56118021
  276.56272377  893.24226     932.4482        0.            0.
  118.51304512    0.            0.            0.            0.        ]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [ 533.57681414 1087.58074772    0.          262.00089533 1292.05698054
    0.         1066.64996966 1226.90550586    0.          141.62492992
  162.69885274  480.24320653 1096.72411323  873.78797517   66.50618548
  259.96615907    0.          668.4865808   540.74348129  482.90693062]
self.args.diff: None
self.reward: -0.004665669374466234
sum end_total_asset(stocks): 8226.974424957165
self.state[0](cash): 91768.95322270249
today cost: -1.6169768574156738
size: 1
next_state_batch [[8.98001250e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2647, -0.0530,  0.8725, -0.4307, -0.2218, -1.4205, -1.3765,  0.7699,
         -0.0599,  0.5701,  0.7512,  1.9848,  1.5195, -1.4647, -0.7221,  0.4202,
         -0.7817, -0.1569, -1.0516, -0.4134]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.0265]], device='cuda:0')
value_loss: tensor(3606.5413, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2923, -0.0296,  0.8372, -0.4208, -0.2035, -1.4487, -1.3511,  0.7412,
         -0.0394,  0.5886,  0.7750,  2.0043,  1.4961, -1.4453, -0.7040,  0.3843,
         -0.7566, -0.1828, -1.0945, -0.4428]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[3.4751]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(3.4751, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 4

step: 4
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3159, -0.0070,  0.8038, -0.4112, -0.1849, -1.4777, -1.3248,  0.7111,
         -0.0202,  0.6082,  0.7981,  2.0211,  1.4730, -1.4264, -0.6858,  0.3482,
         -0.7333, -0.2122, -1.1374, -0.4584]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3159117  -0.00698066  0.80377126 -0.41119102 -0.18485722 -1.4776945
 -1.3248435   0.7110687  -0.02022461  0.608186    0.79812     2.0211043
  1.4729887  -1.4263792  -0.6858408   0.34818453 -0.7333429  -0.21219417
 -1.1373875  -0.45839888] <class 'numpy.ndarray'>
action2: [ 1.3456498   0.01414063  0.8018458  -0.3840004  -0.17781603 -1.5094523
 -1.3777103   0.7202396   0.03126791  0.6229186   0.76135397  2.0676472
  1.4442433  -1.413255   -0.62372094  0.34386408 -0.766769   -0.23585054
 -1.0712959  -0.44245726]
action3:   0%|          | 5/200000 [00:09<124:32:38,  2.24s/it][ 1.          0.01414063  0.8018458  -0.3840004  -0.17781603 -1.
 -1.          0.7202396   0.03126791  0.6229186   0.76135397  1.
  1.         -1.         -0.62372094  0.34386408 -0.766769   -0.23585054
 -1.         -0.44245726]
day: 1 train
actions: [ 10.           0.14140631   8.018457    -3.840004    -1.7781603
 -10.         -10.           7.202396     0.31267914   6.229186
   7.6135397   10.          10.         -10.          -6.2372093
   3.4386408   -7.66769     -2.3585055  -10.          -4.4245725 ]
argsort_actions: [ 5  6 18 13 16 14 19  3 17  4  1  8 15  9  7 10  2 11 12  0]
sell index:[ 5  6 18 13 16 14 19  3 17  4]  buy index:[ 0 12 11  2 10  7  9 15  8  1] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [20.0, 0.14140631258487701, 16.340200424194336, 0, 0, 0, 0, 14.61648416519165, 0.31267914175987244, 12.097840309143066, 14.966897964477539, 20.0, 20.0, 0, 0, 7.356233835220337, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [10.          0.14140631  8.01845741  0.          0.          0.
  0.          7.20239592  0.31267914  6.22918606  7.6135397  10.
 10.          0.          0.          3.43864083  0.          0.
  0.          0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8344901560701163, 0.01047376029050533, 0.00019103048729763697, 0.08690519748899607, 0.0, 0.0, 0.0, 0.0, 0.019520095565214342, 7.53105923075357e-05, 0.0034664498418024436, 0.005705144538577309, 0.01810517299620007, 0.018815201767486644, 0.0, 0.0, 0.0022524803614962586, 0.0, 0.0, 0.0, 0.0]
y_w: [0.8344901560701163, 0.010507342332121698, 0.00019408197098168874, 0.08887788933848213, 0.0, 0.0, 0.0, 0.0, 0.01965430429467047, 7.61477004449533e-05, 0.0035253792844026754, 0.005789718280013299, 0.018372571439141765, 0.019007582910712983, 0.0, 0.0, 0.002282882205982989, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0027780558270711
end_total_asset [1.04873672e+03 1.91278663e+01 8.70180997e+03 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.95454550e+03
 7.54084315e+00 3.47095325e+02 5.71255634e+02 1.81286942e+03
 1.88396454e+03 0.00000000e+00 0.00000000e+00 2.25540665e+02
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
begin_total_asset [ 524.36836       0.         4431.66084025    0.            0.
    0.            0.          991.42670886    0.          168.37571049
  280.66252249  906.43471     941.98227       0.            0.
  120.11262185    0.            0.            0.            0.        ]
self.daybefore_end_total_asset [ 522.69245       0.         4333.2977796     0.            0.
    0.            0.          984.65678625    0.          165.56118021
  276.56272377  893.24226     932.4482        0.            0.
  118.51304512    0.            0.            0.            0.        ]
self.args.diff: None
self.reward: 0.013398662493450684
sum end_total_asset(stocks): 16572.48648396969
self.state[0](cash): 83557.42778862448
today cost: 4.0626940563107405
size: 1
next_state_batch [[8.98001250e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2647, -0.0530,  0.8724, -0.4307, -0.2218, -1.4206, -1.3764,  0.7699,
         -0.0599,  0.5701,  0.7512,  1.9848,  1.5195, -1.4646, -0.7220,  0.4201,
         -0.7817, -0.1569, -1.0517, -0.4134]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-20.9887]], device='cuda:0')
value_loss: tensor(306.4857, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3158, -0.0076,  0.8038, -0.4110, -0.1849, -1.4781, -1.3250,  0.7109,
         -0.0202,  0.6082,  0.7982,  2.0208,  1.4734, -1.4265, -0.6858,  0.3485,
         -0.7338, -0.2117, -1.1368, -0.4582]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[45.2932]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(45.2932, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 5

step: 5
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3338,  0.0157,  0.7702, -0.4006, -0.1656, -1.5081, -1.2980,  0.6814,
         -0.0046,  0.6284,  0.8196,  2.0365,  1.4505, -1.4102, -0.6661,  0.3118,
         -0.7104, -0.2437, -1.1803, -0.4602]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3338032   0.01570535  0.7702481  -0.4006463  -0.16556528 -1.5080642
 -1.2979635   0.6814162  -0.00462103  0.6283682   0.8195815   2.0364566
  1.4504858  -1.4102328  -0.6660714   0.31177133 -0.7104085  -0.24374335
 -1.1802711  -0.46024898] <class 'numpy.ndarray'>
action2: [ 1.3360289   0.0566959   0.7672838  -0.37518337 -0.16517152 -1.5295622
 -1.338429    0.6850077   0.00308632  0.65363455  0.7877131   2.0891101
  1.4059201  -1.3812006  -0.606033    0.26823375 -0.7142518  -0.28505966
 -1.1213573  -0.44272456]
action3: [ 1.          0.0566959   0.7672838  -0.37518337 -0.16517152 -1.
 -1.          0.6850077   0.00308632  0.65363455  0.7877131   1.
  1.         -1.         -0.606033    0.26823375 -0.7142518  -0.28505966
 -1.         -0.44272456]
day: 2 train
Reached the end.
self.asset_memory: [100000, 99995.92764765966, 100129.91427259418]
previous_total_asset:100000
end_total_asset:100129.91427259418
total_reward:129.91427259417833
total_cost:  8.135046396664537
total trades:  18
size: 1
next_state_batch [[8.98001250e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2648, -0.0530,  0.8723, -0.4306, -0.2217, -1.4207, -1.3763,  0.7698,
         -0.0598,  0.5702,  0.7513,  1.9849,  1.5194, -1.4646, -0.7220,  0.4201,
         -0.7817, -0.1570, -1.0518, -0.4135]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[0.0045]], device='cuda:0')
value_loss: tensor(1802.5104, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3335,  0.0146,  0.7704, -0.4003, -0.1654, -1.5086, -1.2984,  0.6809,
         -0.0046,  0.6285,  0.8199,  2.0357,  1.4512, -1.4106, -0.6660,  0.3125,
         -0.7111, -0.2431, -1.1791, -0.4598]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[43.7575]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(43.7575, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 6
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3507,  0.0348,  0.7375, -0.3951, -0.1461, -1.5388, -1.2701,  0.6523,
          0.0132,  0.6499,  0.8307,  2.0495,  1.4299, -1.4005, -0.6430,  0.2770,
         -0.6862, -0.2727, -1.2190, -0.4540]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.350744    0.03480368  0.7374967  -0.395059   -0.14612675 -1.538783
 -1.2701364   0.6522513   0.01315926  0.6499165   0.83071876  2.0494967
  1.4298561  -1.4005146  -0.6430485   0.27702743 -0.6861737  -0.27268693
 -1.2189512  -0.4539907 ] <class 'numpy.ndarray'>
action2:   0%|          | 6/200000 [00:11<136:30:22,  2.46s/it]  0%|          | 7/200000 [00:14<143:19:50,  2.58s/it][ 1.365011    0.082382    0.7107141  -0.35362312 -0.16035394 -1.5473613
 -1.3219092   0.6535369  -0.04301135  0.6754772   0.7954873   2.099713
  1.3891276  -1.3882465  -0.5495871   0.23019728 -0.6913489  -0.33687773
 -1.164912   -0.44852307]
action3: [ 1.          0.082382    0.7107141  -0.35362312 -0.16035394 -1.
 -1.          0.6535369  -0.04301135  0.6754772   0.7954873   1.
  1.         -1.         -0.5495871   0.23019728 -0.6913489  -0.33687773
 -1.         -0.44852307]

step: 6
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3502,  0.0324,  0.7376, -0.3946, -0.1459, -1.5401, -1.2714,  0.6515,
          0.0131,  0.6505,  0.8307,  2.0482,  1.4310, -1.4017, -0.6428,  0.2782,
         -0.6867, -0.2704, -1.2166, -0.4532]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3502163   0.03240022  0.7376375  -0.39459428 -0.1459289  -1.5401222
 -1.2713885   0.65150833  0.01307078  0.65049255  0.830687    2.048209
  1.4310238  -1.40167    -0.6428197   0.27820152 -0.6866883  -0.270366
 -1.2166319  -0.45323697] <class 'numpy.ndarray'>
action2: [ 1.3456274   0.04730057  0.7194424  -0.39525187 -0.18127184 -1.5171525
 -1.2124844   0.6632919  -0.00558834  0.6249973   0.83042157  2.037576
  1.4439231  -1.4442159  -0.6541738   0.2675248  -0.6795327  -0.26923442
 -1.201117   -0.45713493]
action3: [ 1.          0.04730057  0.7194424  -0.39525187 -0.18127184 -1.
 -1.          0.6632919  -0.00558834  0.6249973   0.83042157  1.
  1.         -1.         -0.6541738   0.2675248  -0.6795327  -0.26923442
 -1.         -0.45713493]
day: 0 train
actions: [ 10.           0.47300574   7.194424    -3.9525187   -1.8127184
 -10.         -10.           6.632919    -0.05588342   6.2499733
   8.304215    10.          10.         -10.          -6.541738
   2.6752481   -6.795327    -2.6923442  -10.          -4.571349  ]
argsort_actions: [ 5  6 18 13 16 14 19  3 17  4  8  1 15  9  7  2 10 11 12  0]
sell index:[ 5  6 18 13 16 14 19  3 17  4  8]  buy index:[ 0 12 11 10  2  7  9 15  1] 
self.sell_num, self.buy_num, self.hold_num: 0 9 11
self.state[HOLDING_IDX~EMB_IDX]: [10.0, 0.4730057418346405, 7.194424152374268, 0, 0, 0, 0, 6.632918834686279, 0, 6.249973297119141, 8.304215431213379, 10.0, 10.0, 0, 0, 2.675248146057129, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [-10.           0.33159943  -9.14577627   0.           0.
   0.           0.          -7.98356533  -0.31267914  -5.84786701
  -6.66268253 -10.         -10.           0.           0.
  -4.68098569   0.           0.           0.           0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio [0.9239158901598575, 0.005227121354519403, 0.0006297932310651368, 0.037464214270262926, 0.0, 0.0, 0.0, 0.0, 0.008809437246282411, 0.0, 0.00176325249629403, 0.0031233660180535806, 0.008932759009634007, 0.009324833175231782, 0.0, 0.0, 0.0008093330387991428, 0.0, 0.0, 0.0, 0.0]
y_w: [0.9239158901598575, 0.005227121354519403, 0.0006297932310651368, 0.037464214270262926, 0.0, 0.0, 0.0, 0.0, 0.008809437246282411, 0.0, 0.00176325249629403, 0.0031233660180535806, 0.008932759009634007, 0.009324833175231782, 0.0, 0.0, 0.0008093330387991428, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0
end_total_asset [ 522.69245      62.97695129 3746.28033599    0.            0.
    0.            0.          880.9105481     0.          176.31860918
  312.32483914  893.24226     932.4482        0.            0.
   80.93025591    0.            0.            0.            0.        ]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [1.04873672e+03 1.91278663e+01 8.70180997e+03 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.95454550e+03
 7.54084315e+00 3.47095325e+02 5.71255634e+02 1.81286942e+03
 1.88396454e+03 0.00000000e+00 0.00000000e+00 2.25540665e+02
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
self.args.diff: None
self.reward: -0.013368029419673258
sum end_total_asset(stocks): 7608.124449612973
self.state[0](cash): 92388.10952878447
today cost: -4.3690247941061156
size: 1
size: 1
next_state_batch [[9.17689532e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2649, -0.0529,  0.8720, -0.4307, -0.2217, -1.4209, -1.3764,  0.7699,
         -0.0598,  0.5703,  0.7512,  1.9850,  1.5192, -1.4646, -0.7219,  0.4197,
         -0.7812, -0.1567, -1.0520, -0.4136]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.4419]], device='cuda:0')
value_loss: tensor(743.4456, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3502,  0.0325,  0.7376, -0.3947, -0.1459, -1.5401, -1.2714,  0.6515,
          0.0131,  0.6504,  0.8307,  2.0482,  1.4311, -1.4017, -0.6429,  0.2783,
         -0.6868, -0.2704, -1.2166, -0.4532]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[34.6462]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(34.6462, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 7

step: 7
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3647,  0.0516,  0.7047, -0.3873, -0.1258, -1.5700, -1.2433,  0.6215,
          0.0319,  0.6718,  0.8404,  2.0618,  1.4092, -1.3887, -0.6195,  0.2432,
         -0.6624, -0.3014, -1.2571, -0.4455]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3647422   0.05157803  0.70470166 -0.38727784 -0.12583783 -1.5700109
 -1.2432672   0.62152296  0.03191925  0.67179674  0.8404392   2.0618308
  1.4092015  -1.3886938  -0.61953723  0.24323891 -0.6623871  -0.3013985
 -1.2570988  -0.44546184] <class 'numpy.ndarray'>
action2: [ 1.4054778   0.09415148  0.7105405  -0.4097149  -0.1692213  -1.54533
 -1.1888229   0.6171988   0.0173737   0.6162419   0.84610116  2.0525131
  1.4156659  -1.4328403  -0.604394    0.22478595 -0.6357117  -0.3313434
 -1.1962509  -0.45784408]
action3: [ 1.          0.09415148  0.7105405  -0.4097149  -0.1692213  -1.
 -1.          0.6171988   0.0173737   0.6162419   0.84610116  1.
  1.         -1.         -0.604394    0.22478595 -0.6357117  -0.3313434
 -1.         -0.45784408]
day: 1 train
actions: [ 10.           0.94151485   7.105405    -4.097149    -1.6922129
 -10.         -10.           6.1719885    0.17373699   6.162419
   8.461012    10.          10.         -10.          -6.04394
   2.2478595   -6.357117    -3.3134341  -10.          -4.5784407 ]
argsort_actions: [ 5  6 18 13 16 14 19  3 17  4  8  1 15  9  7  2 10 11 12  0]
sell index:[ 5  6 18 13 16 14 19  3 17  4]  buy index:[ 0 12 11 10  2  7  9 15  1  8] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [20.0, 1.4145205914974213, 14.299829006195068, 0, 0, 0, 0, 12.804907321929932, 0.17373698949813843, 12.412392139434814, 16.76522731781006, 20.0, 20.0, 0, 0, 4.923107624053955, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [10.          0.94151485  7.10540485  0.          0.          0.
  0.          6.17198849  0.17373699  6.16241884  8.46101189 10.
 10.          0.          0.          2.24785948  0.          0.
  0.          0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices:   0%|          | 8/200000 [00:17<148:58:28,  2.68s/it]  0%|          | 9/200000 [00:20<154:11:39,  2.78s/it][52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8460253040879842, 0.010475042880832593, 0.001911156885331704, 0.07606281521031397, 0.0, 0.0, 0.0, 0.0, 0.017102855954939922, 4.185069005160821e-05, 0.003557015354696263, 0.006391421797365416, 0.018107390110122315, 0.018817505829745385, 0.0, 0.0, 0.0015076411986166822, 0.0, 0.0, 0.0, 0.0]
y_w: [0.8460253040879842, 0.010508629034821266, 0.0019416853320511354, 0.0777893919853492, 0.0, 0.0, 0.0, 0.0, 0.017220445162437148, 4.2315877645083524e-05, 0.0036174844056673637, 0.006486168994538711, 0.018374821298004405, 0.019009910531482384, 0.0, 0.0, 0.0015279899102172952, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.002544146620198
end_total_asset [1.04873672e+03 1.91340544e+02 7.61523062e+03 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.71229782e+03
 4.18999291e+00 3.56120033e+02 6.39894157e+02 1.81286942e+03
 1.88396454e+03 0.00000000e+00 0.00000000e+00 1.50941500e+02
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
begin_total_asset [ 524.36836      63.98293281 3831.31847983    0.            0.
    0.            0.          886.96717241    0.          179.31601513
  316.95477972  906.43471     941.98227       0.            0.
   82.02257578    0.            0.            0.            0.        ]
self.daybefore_end_total_asset [ 522.69245      62.97695129 3746.28033599    0.            0.
    0.            0.          880.9105481     0.          176.31860918
  312.32483914  893.24226     932.4482        0.            0.
   80.93025591    0.            0.            0.            0.        ]
self.args.diff: None
self.reward: 0.012142013822634181
sum end_total_asset(stocks): 15415.585348031527
self.state[0](cash): 84702.06876859225
today cost: 3.8027078359163773
size: 1
size: 1
next_state_batch [[9.23881095e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2650, -0.0529,  0.8719, -0.4306, -0.2216, -1.4210, -1.3763,  0.7697,
         -0.0597,  0.5705,  0.7512,  1.9851,  1.5192, -1.4645, -0.7218,  0.4196,
         -0.7811, -0.1568, -1.0521, -0.4136]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.5976]], device='cuda:0')
value_loss: tensor(170.8791, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3645,  0.0505,  0.7048, -0.3870, -0.1258, -1.5706, -1.2439,  0.6212,
          0.0319,  0.6721,  0.8404,  2.0613,  1.4097, -1.3893, -0.6195,  0.2438,
         -0.6626, -0.3003, -1.2560, -0.4451]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[17.6087]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(17.6087, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 8

step: 8
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3781,  0.0696,  0.6737, -0.3787, -0.1057, -1.6006, -1.2157,  0.5920,
          0.0507,  0.6942,  0.8503,  2.0696,  1.3878, -1.3737, -0.5964,  0.2099,
         -0.6380, -0.3334, -1.2987, -0.4350]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3781106   0.06961147  0.67370373 -0.37869617 -0.10568418 -1.6005596
 -1.2156785   0.5919534   0.05073342  0.69423497  0.85026777  2.0695739
  1.3877542  -1.3737465  -0.59642714  0.2098867  -0.638017   -0.33337435
 -1.2986891  -0.43495777] <class 'numpy.ndarray'>
action2: [ 1.4265041   0.06861275  0.712749   -0.40794966 -0.18021114 -1.5706443
 -1.1372072   0.56177217  0.03924924  0.59890074  0.87382066  2.0655878
  1.3827138  -1.4244546  -0.5947765   0.16314985 -0.63385504 -0.36553884
 -1.2258315  -0.4184784 ]
action3: [ 1.          0.06861275  0.712749   -0.40794966 -0.18021114 -1.
 -1.          0.56177217  0.03924924  0.59890074  0.87382066  1.
  1.         -1.         -0.5947765   0.16314985 -0.63385504 -0.36553884
 -1.         -0.4184784 ]
day: 2 train
Reached the end.
self.asset_memory: [100000, 99996.23397839745, 100117.65411662377]
previous_total_asset:100000
end_total_asset:100117.65411662377
total_reward:117.654116623773
total_cost:  7.568729438474799
total trades:  19
size: 1
next_state_batch [[9.58723016e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2649, -0.0532,  0.8716, -0.4305, -0.2215, -1.4215, -1.3763,  0.7695,
         -0.0597,  0.5707,  0.7515,  1.9848,  1.5194, -1.4646, -0.7218,  0.4197,
         -0.7813, -0.1565, -1.0519, -0.4133]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-22.4041]], device='cuda:0')
value_loss: tensor(22.4697, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3776,  0.0674,  0.6738, -0.3784, -0.1055, -1.6019, -1.2170,  0.5913,
          0.0506,  0.6947,  0.8503,  2.0684,  1.3890, -1.3748, -0.5963,  0.2111,
         -0.6386, -0.3311, -1.2965, -0.4342]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[5.5842]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(5.5842, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 9
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3910,  0.0855,  0.6455, -0.3691, -0.0854, -1.6327, -1.1895,  0.5629,
          0.0688,  0.7182,  0.8612,  2.0681,  1.3681, -1.3580, -0.5734,  0.1794,
         -0.6138, -0.3650, -1.3402, -0.4218]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3910475   0.08554718  0.64547944 -0.36914885 -0.08536839 -1.6326544
 -1.1895293   0.5629191   0.0688424   0.7181656   0.86122704  2.0681028
  1.3681177  -1.3579588  -0.573351    0.17941754 -0.6138286  -0.3650469
 -1.3401924  -0.4217872 ] <class 'numpy.ndarray'>
action2: [ 1.4026763   0.0959345   0.6503372  -0.4065174  -0.15470289 -1.5946454
 -1.1063559   0.5391107   0.08372515  0.6007812   0.8591666   2.066212
  1.3708858  -1.3737926  -0.54260355  0.16608766 -0.6154265  -0.38705665
 -1.2630591  -0.4016789 ]
action3: [ 1.          0.0959345   0.6503372  -0.4065174  -0.15470289 -1.
 -1.          0.5391107   0.08372515  0.6007812   0.8591666   1.
  1.         -1.         -0.54260355  0.16608766 -0.6154265  -0.38705665
 -1.         -0.4016789 ]

step: 9
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3905,  0.0833,  0.6456, -0.3688, -0.0852, -1.6339, -1.1908,  0.5623,
          0.0687,  0.7187,  0.8613,  2.0670,  1.3693, -1.3591, -0.5733,  0.1806,
         -0.6144, -0.3628, -1.3380, -0.4211]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.3905267   0.08334952  0.6456299  -0.368762   -0.085246   -1.6339483
 -1.1907768   0.56234527  0.06869445  0.71866244  0.86134297  2.066962
  1.369294   -1.359087   -0.5733097   0.1805833  -0.61443573 -0.3627646
 -1.3379718  -0.42108795] <class 'numpy.ndarray'>
action2: [ 1.3947009   0.12131865  0.644323   -0.38820642 -0.08167429 -1.6463952
 -1.1666118   0.5747183   0.08128873  0.73453414  0.87644565  2.111215
  1.3532177  -1.3733959  -0.5817428   0.17640749 -0.6395132  -0.34089926
 -1.3383032  -0.45905685]
action3: [ 1.          0.12131865  0.644323   -0.38820642 -0.08167429 -1.
 -1.          0.5747183   0.08128873  0.73453414  0.87644565  1.
  1.         -1.         -0.5817428   0.17640749 -0.6395132  -0.34089926
 -1.         -0.45905685]
day: 0 train
actions:   0%|          | 10/200000 [00:23<152:35:10,  2.75s/it][ 10.           1.2131865    6.4432297   -3.8820643   -0.8167429
 -10.         -10.           5.747183     0.81288725   7.3453417
   8.764457    10.          10.         -10.          -5.817428
   1.7640748   -6.395132    -3.4089925  -10.          -4.5905685 ]
argsort_actions: [ 5  6 18 13 16 14 19  3 17  4  8  1 15  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 16 14 19  3 17  4]  buy index:[ 0 12 11 10  9  2  7 15  1  8] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [10.0, 1.213186502456665, 6.443229675292969, 0, 0, 0, 0, 5.747182846069336, 0.8128872513771057, 7.345341682434082, 8.764456748962402, 10.0, 10.0, 0, 0, 1.7640748023986816, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [-10.          -0.20133409  -7.85659933   0.           0.
   0.           0.          -7.05772448   0.63915026  -5.06705046
  -8.00077057 -10.         -10.           0.           0.
  -3.15903282   0.           0.           0.           0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio [0.927618267865663, 0.005227111775255277, 0.0016153191800314794, 0.03355238580058054, 0.0, 0.0, 0.0, 0.0, 0.007633042873473824, 0.0001938947899084837, 0.0020722757852870586, 0.0032964650828535306, 0.008932742639388872, 0.009324816086468415, 0.0, 0.0, 0.0005336781210895007, 0.0, 0.0, 0.0, 0.0]
y_w: [0.927618267865663, 0.005227111775255277, 0.0016153191800314794, 0.03355238580058054, 0.0, 0.0, 0.0, 0.0, 0.007633042873473824, 0.0001938947899084837, 0.0020722757852870586, 0.0032964650828535306, 0.008932742639388872, 0.009324816086468415, 0.0, 0.0, 0.0005336781210895007, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 0.9999999999999999
end_total_asset [ 522.69245     161.52613069 3355.11836966    0.            0.
    0.            0.          763.27693993   19.38878431  207.22015405
  329.63469782  893.24226     932.4482        0.            0.
   53.36590006    0.            0.            0.            0.        ]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [1.04873672e+03 1.91340544e+02 7.61523062e+03 0.00000000e+00
 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.71229782e+03
 4.18999291e+00 3.56120033e+02 6.39894157e+02 1.81286942e+03
 1.88396454e+03 0.00000000e+00 0.00000000e+00 1.50941500e+02
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
self.args.diff: None
self.reward: -0.012123688399759703
sum end_total_asset(stocks): 7237.913886525347
self.state[0](cash): 92758.50334610083
today cost: -3.9859620646447524
size: 1
size: 1
next_state_batch [[9.17689532e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2653, -0.0525,  0.8715, -0.4306, -0.2213, -1.4214, -1.3760,  0.7694,
         -0.0595,  0.5707,  0.7514,  1.9853,  1.5190, -1.4643, -0.7216,  0.4191,
         -0.7807, -0.1572, -1.0527, -0.4137]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.4426]], device='cuda:0')
value_loss: tensor(249.9373, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.3906,  0.0834,  0.6456, -0.3688, -0.0852, -1.6339, -1.1908,  0.5624,
          0.0687,  0.7187,  0.8613,  2.0670,  1.3693, -1.3591, -0.5733,  0.1806,
         -0.6144, -0.3627, -1.3380, -0.4211]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[2.1855]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(2.1855, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 10

step: 10
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4028,  0.0992,  0.6197, -0.3587, -0.0649, -1.6658, -1.1641,  0.5341,
          0.0863,  0.7431,  0.8725,  2.0605,  1.3494, -1.3414, -0.5504,  0.1512,
         -0.5897, -0.3961, -1.3811, -0.4067]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4027977   0.09923231  0.6196809  -0.35866013 -0.06486508 -1.6658208
 -1.164126    0.53406376  0.08626183  0.74314225  0.87250453  2.0605335
  1.3493754  -1.3413736  -0.55044407  0.15121607 -0.589673   -0.39610043
 -1.3810824  -0.40666294] <class 'numpy.ndarray'>
action2: [ 1.4308811   0.1517088   0.62232846 -0.3915746  -0.03117142 -1.6525229
 -1.1411989   0.55989623  0.1059591   0.74291116  0.9117964   2.0934117
  1.3588178  -1.3317597  -0.60321826  0.1298163  -0.6255453  -0.3979985
 -1.3614893  -0.43466732]
action3: [ 1.          0.1517088   0.62232846 -0.3915746  -0.03117142 -1.
 -1.          0.55989623  0.1059591   0.74291116  0.9117964   1.
  1.         -1.         -0.60321826  0.1298163  -0.6255453  -0.3979985
 -1.         -0.43466732]
day: 1 train
actions: [ 10.          1.5170879   6.2232847  -3.915746   -0.3117142 -10.
 -10.          5.5989623   1.059591    7.4291115   9.117964   10.
  10.        -10.         -6.0321827   1.2981629  -6.255453   -3.9799852
 -10.         -4.346673 ]
argsort_actions: [ 5  6 18 13 16 14 19 17  3  4  8 15  1  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 16 14 19 17  3  4]  buy index:[ 0 12 11 10  9  2  7  1 15  8] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [20.0, 2.7302744388580322, 12.66651439666748, 0, 0, 0, 0, 11.346145153045654, 1.8724783062934875, 14.774453163146973, 17.882420539855957, 20.0, 20.0, 0, 0, 3.0622377395629883, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [10.          1.51708794  6.22328472  0.          0.          0.
  0.          5.59896231  1.05959105  7.42911148  9.11796379 10.
 10.          0.          0.          1.29816294  0.          0.
  0.          0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8539313209278083, 0.010475785753957157, 0.0036891317630501474, 0.06737976166469703, 0.0, 0.0, 0.0, 0.0, 0.015155537102719956, 0.00045108452112512963, 0.0042342107096667355, 0.006817813788848652, 0.01810867425698661, 0.018818840336869723, 0.0, 0.0, 0.0009378391742705584, 0.0, 0.0, 0.0, 0.0]
y_w: [0.8539313209278083, 0.01050937428982163, 0.003748061233118059, 0.06890923873277563, 0.0, 0.0, 0.0, 0.0, 0.01525973768780346, 0.00045609851068127314, 0.004306192041680716, 0.006918881871635666, 0.018376124410656662, 0.019011258683637445, 0.0, 0.0, 0.0009504972383394487, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0023767856279584
end_total_asset [1048.73672     369.32102619 6745.42529814    0.            0.
    0.            0.         1517.22922216   45.15832151  423.88918175
  682.53511846 1812.86942    1883.96454       0.            0.
   93.88759971    0.            0.            0.            0.        ]
begin_total_asset   0%|          | 11/200000 [00:26<152:47:32,  2.75s/it]  0%|          | 12/200000 [00:29<156:17:58,  2.81s/it][ 524.36836     164.10631755 3431.27738953    0.            0.
    0.            0.          768.52478454   19.6042986   210.74288443
  334.5212418   906.43471     941.98227       0.            0.
   54.08618239    0.            0.            0.            0.        ]
self.daybefore_end_total_asset [ 522.69245     161.52613069 3355.11836966    0.            0.
    0.            0.          763.27693993   19.38878431  207.22015405
  329.63469782  893.24226     932.4482        0.            0.
   53.36590006    0.            0.            0.            0.        ]
self.args.diff: None
self.reward: 0.011413720514922171
sum end_total_asset(stocks): 14623.016447910592
self.state[0](cash): 85487.53798986481
today cost: 3.597347164490402
size: 1
next_state_batch [[9.23881095e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2654, -0.0525,  0.8713, -0.4305, -0.2212, -1.4217, -1.3758,  0.7692,
         -0.0594,  0.5709,  0.7516,  1.9854,  1.5188, -1.4643, -0.7214,  0.4189,
         -0.7806, -0.1574, -1.0530, -0.4137]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.5875]], device='cuda:0')
value_loss: tensor(374.6256, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4025,  0.0982,  0.6198, -0.3584, -0.0649, -1.6665, -1.1648,  0.5338,
          0.0863,  0.7434,  0.8726,  2.0600,  1.3500, -1.3419, -0.5504,  0.1518,
         -0.5900, -0.3951, -1.3800, -0.4063]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[6.4044]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(6.4044, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 11

step: 11
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4129,  0.1146,  0.5957, -0.3480, -0.0440, -1.6976, -1.1375,  0.5053,
          0.1031,  0.7683,  0.8831,  2.0509,  1.3294, -1.3227, -0.5270,  0.1229,
         -0.5642, -0.4299, -1.4243, -0.3911]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4129016   0.11460694  0.5957461  -0.34798503 -0.04395516 -1.6976161
 -1.1375297   0.5052974   0.10311873  0.7683187   0.88313043  2.0509257
  1.3293711  -1.3226742  -0.5270125   0.12289027 -0.56424886 -0.42992875
 -1.4242815  -0.39107484] <class 'numpy.ndarray'>
action2: [ 1.4559704   0.16460097  0.61383677 -0.38913336 -0.02509709 -1.6579189
 -1.1480622   0.5624195   0.1091343   0.7688598   0.9579163   2.0942748
  1.3454114  -1.3437529  -0.5823014   0.11487817 -0.59082824 -0.42313614
 -1.4171253  -0.42269874]
action3: [ 1.          0.16460097  0.61383677 -0.38913336 -0.02509709 -1.
 -1.          0.5624195   0.1091343   0.7688598   0.9579163   1.
  1.         -1.         -0.5823014   0.11487817 -0.59082824 -0.42313614
 -1.         -0.42269874]
day: 2 train
Reached the end.
self.asset_memory: [100000, 99996.41723262618, 100110.5544377754]
previous_total_asset:100000
end_total_asset:100110.5544377754
total_reward:110.55443777539767
total_cost:  7.180114538320448
total trades:  20
size: 1
next_state_batch [[8.54875380e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2659, -0.0513,  0.8711, -0.4307, -0.2211, -1.4214, -1.3752,  0.7692,
         -0.0592,  0.5708,  0.7517,  1.9861,  1.5182, -1.4637, -0.7213,  0.4180,
         -0.7802, -0.1587, -1.0545, -0.4140]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-19.9732]], device='cuda:0')
value_loss: tensor(195.5749, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4126,  0.1136,  0.5957, -0.3478, -0.0439, -1.6983, -1.1381,  0.5051,
          0.1030,  0.7686,  0.8832,  2.0504,  1.3300, -1.3232, -0.5270,  0.1235,
         -0.5646, -0.4288, -1.4232, -0.3907]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[13.3649]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(13.3649, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 12
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4205,  0.1285,  0.5737, -0.3365, -0.0225, -1.7300, -1.1114,  0.4761,
          0.1193,  0.7943,  0.8928,  2.0383,  1.3097, -1.3036, -0.5031,  0.0961,
         -0.5385, -0.4631, -1.4662, -0.3742]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4204619   0.12854794  0.5737174  -0.336525   -0.02252723 -1.7300279
 -1.1114153   0.4760729   0.1192948   0.7942799   0.89279425  2.0382888
  1.3096739  -1.3035631  -0.5031081   0.09607772 -0.53846496 -0.46313217
 -1.4662216  -0.37422362] <class 'numpy.ndarray'>
action2: [ 1.4562585   0.18790264  0.58833694 -0.34545702 -0.01956579 -1.6865546
 -1.1629422   0.52600014  0.15310994  0.80733806  0.9356248   2.0617442
  1.3425204  -1.2899864  -0.56939507  0.09442705 -0.55293983 -0.456823
 -1.457807   -0.41144654]
action3: [ 1.          0.18790264  0.58833694 -0.34545702 -0.01956579 -1.
 -1.          0.52600014  0.15310994  0.80733806  0.9356248   1.
  1.         -1.         -0.56939507  0.09442705 -0.55293983 -0.456823
 -1.         -0.41144654]

step: 12
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4200,  0.1264,  0.5740, -0.3362, -0.0225, -1.7313, -1.1127,  0.4756,
          0.1190,  0.7948,  0.8929,  2.0372,  1.3109, -1.3047, -0.5031,  0.0974,
         -0.5391, -0.4609, -1.4641, -0.3736]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4199878   0.12642057  0.57397467 -0.33619708 -0.02248343 -1.7312912
 -1.1127222   0.475572    0.11902577  0.79477465  0.8928827   2.0372317
  1.3109423  -1.3046838  -0.5030978   0.09735712 -0.5391173  -0.4608607
 -1.4641107  -0.373605  ] <class 'numpy.ndarray'>
action2: [ 1.4029578   0.12572004  0.59579796 -0.33409467 -0.01820369 -1.7231921
 -1.1187911   0.50144005  0.13981341  0.78591967  0.87731665  2.045492
  1.315972   -1.3003318  -0.5184795   0.0689797  -0.5390653  -0.44277117
 -1.4729295  -0.38025683]
action3: [ 1.          0.12572004  0.59579796 -0.33409467 -0.01820369 -1.
 -1.          0.50144005  0.13981341  0.78591967  0.87731665  1.
  1.         -1.         -0.5184795   0.0689797  -0.5390653  -0.44277117
 -1.         -0.38025683]
day: 0 train
actions: [ 10.           1.2572004    5.9579797   -3.3409467   -0.18203692
 -10.         -10.           5.0144005    1.3981341    7.8591967
   8.773167    10.          10.         -10.          -5.1847954
   0.6897969   -5.390653    -4.4277115  -10.          -3.8025684 ]
argsort_actions: [ 5  6 18 13 16 14 17 19  3  4 15  1  8  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 16 14 17 19  3  4]  buy index:[ 0 12 11 10  9  2  7  8  1 15] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [10.0, 1.2572003602981567, 5.957979679107666, 0, 0, 0, 0, 5.014400482177734, 1.3981341123580933, 7.859196662902832, 8.77316665649414, 10.0, 10.0, 0, 0, 0.6897969245910645, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [-10.          -1.47307408  -6.70853472   0.           0.
   0.           0.          -6.33174467  -0.47434419  -6.9152565
  -9.10925388 -10.         -10.           0.           0.
  -2.37244081   0.           0.           0.           0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio   0%|          | 13/200000 [00:31<155:07:57,  2.79s/it][0.9310970574458578, 0.005227102774486886, 0.0016739193472236204, 0.031025448204759446, 0.0, 0.0, 0.0, 0.0, 0.006659796457312391, 0.00033349084109541297, 0.0022172412933575384, 0.003299735349070897, 0.008932727257749632, 0.00932480002970256, 0.0, 0.0, 0.0002086809993838543, 0.0, 0.0, 0.0, 0.0]
y_w: [0.9310970574458578, 0.005227102774486886, 0.0016739193472236204, 0.031025448204759446, 0.0, 0.0, 0.0, 0.0, 0.006659796457312391, 0.00033349084109541297, 0.0022172412933575384, 0.003299735349070897, 0.008932727257749632, 0.00932480002970256, 0.0, 0.0, 0.0002086809993838543, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0000000000000002
end_total_asset [ 522.69245     167.38622569 3102.43900572    0.            0.
    0.            0.          665.95693197   33.34794671  221.71656726
  329.9622809   893.24226     932.4482        0.            0.
   20.86738822    0.            0.            0.            0.        ]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [1048.73672     369.32102619 6745.42529814    0.            0.
    0.            0.         1517.22922216   45.15832151  423.88918175
  682.53511846 1812.86942    1883.96454       0.            0.
   93.88759971    0.            0.            0.            0.        ]
self.args.diff: None
self.reward: -0.011396501710734447
sum end_total_asset(stocks): 6890.059256462439
self.state[0](cash): 93106.53016420561
today cost: -3.769535206371542
size: 1
next_state_batch [[8.35574278e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2661, -0.0509,  0.8708, -0.4306, -0.2210, -1.4216, -1.3748,  0.7691,
         -0.0590,  0.5711,  0.7519,  1.9864,  1.5179, -1.4635, -0.7212,  0.4177,
         -0.7799, -0.1592, -1.0551, -0.4140]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[0.0134]], device='cuda:0')
value_loss: tensor(146.7533, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4204,  0.1288,  0.5737, -0.3366, -0.0226, -1.7299, -1.1112,  0.4762,
          0.1192,  0.7943,  0.8928,  2.0384,  1.3096, -1.3034, -0.5031,  0.0961,
         -0.5383, -0.4634, -1.4665, -0.3743]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[15.0692]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(15.0692, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 13

step: 13
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4243e+00,  1.4262e-01,  5.5478e-01, -3.2419e-01, -1.4210e-04,
         -1.7632e+00, -1.0854e+00,  4.4658e-01,  1.3549e-01,  8.2020e-01,
          9.0218e-01,  2.0224e+00,  1.2903e+00, -1.2853e+00, -4.7946e-01,
          7.0388e-02, -5.1254e-01, -4.9563e-01, -1.5065e+00, -3.5685e-01]],
       device='cuda:0', grad_fn=<DivBackward0>)
action1: [ 1.4242704e+00  1.4261700e-01  5.5478024e-01 -3.2419127e-01
 -1.4210420e-04 -1.7632059e+00 -1.0853728e+00  4.4658384e-01
  1.3548738e-01  8.2020217e-01  9.0218347e-01  2.0223701e+00
  1.2902875e+00 -1.2852852e+00 -4.7945622e-01  7.0388138e-02
 -5.1254100e-01 -4.9562788e-01 -1.5065001e+00 -3.5684758e-01] <class 'numpy.ndarray'>
action2: [ 1.4284679   0.09187323  0.56694865 -0.30255562 -0.01880444 -1.7394122
 -1.0810542   0.46991718  0.16359167  0.84605163  0.9162451   2.0583692
  1.2658114  -1.2527045  -0.50549424  0.04455086 -0.5361853  -0.48824763
 -1.5229911  -0.33881906]
action3: [ 1.          0.09187323  0.56694865 -0.30255562 -0.01880444 -1.
 -1.          0.46991718  0.16359167  0.84605163  0.9162451   1.
  1.         -1.         -0.50549424  0.04455086 -0.5361853  -0.48824763
 -1.         -0.33881906]
day: 1 train
actions: [ 10.           0.9187323    5.6694865   -3.025556    -0.18804443
 -10.         -10.           4.699172     1.6359167    8.460516
   9.162451    10.          10.         -10.          -5.054942
   0.44550863  -5.361853    -4.8824763  -10.          -3.3881905 ]
argsort_actions: [ 5  6 18 13 16 14 17 19  3  4 15  1  8  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 16 14 17 19  3  4]  buy index:[ 0 12 11 10  9  2  7  8  1 15] 
self.sell_num, self.buy_num, self.hold_num: 0 10 10
self.state[HOLDING_IDX~EMB_IDX]: [20.0, 2.1759326457977295, 11.627466201782227, 0, 0, 0, 0, 9.71357250213623, 3.0340508222579956, 16.31971263885498, 17.935617446899414, 20.0, 20.0, 0, 0, 1.1353055536746979, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [10.          0.91873229  5.66948652  0.          0.          0.
  0.          4.69917202  1.63591671  8.46051598  9.16245079 10.
 10.          0.          0.          0.44550863  0.          0.
  0.          0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8622272889866519, 0.010476406839385638, 0.002940282502024537, 0.06185619233645363, 0.0, 0.0, 0.0, 0.0, 0.012975608409421495, 0.0007309534639680308, 0.004677343933996007, 0.006838500944060477, 0.01810974787895391, 0.018819956062963085, 0.0, 0.0, 0.0003477186421212345, 0.0, 0.0, 0.0, 0.0]
y_w: [0.8622272889866519, 0.010509997366637745, 0.0029872500002932905, 0.06326028794854652, 0.0, 0.0, 0.0, 0.0, 0.013064821083239139, 0.0007390783116689033, 0.004756858504654453, 0.0069398756956977024, 0.01837721388913317, 0.01901238581777543, 0.0, 0.0, 0.000352411818702754, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0022274694230011
end_total_asset [1048.73672     294.33586098 6192.09059529    0.            0.
    0.            0.         1298.91834213   73.17181836  468.22373461
  684.5655347  1812.86942    1883.96454       0.            0.
   34.80824235    0.            0.            0.            0.        ]
begin_total_asset [ 524.36836     170.06002056 3172.86236724    0.            0.
    0.            0.          670.53566128   33.71862282  225.48573581
  334.85368101  906.43471     941.98227       0.            0.
   21.14903644    0.            0.            0.            0.        ]
self.daybefore_end_total_asset [ 522.69245     167.38622569 3102.43900572    0.            0.
    0.            0.          665.95693197   33.34794671  221.71656726
  329.9622809   893.24226     932.4482        0.            0.
   20.86738822    0.            0.            0.            0.        ]
self.args.diff: None
self.reward: 0.010803004268798395
sum end_total_asset(stocks): 13791.684808426127
self.state[0](cash): 86312.93465492991
today cost: 3.3611659999215164
size: 1
size: 1
next_state_batch [[8.98001250e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2659, -0.0519,  0.8706, -0.4303, -0.2205, -1.4227, -1.3749,  0.7682,
         -0.0588,  0.5715,  0.7523,  1.9857,  1.5184, -1.4638, -0.7208,  0.4181,
         -0.7803, -0.1588, -1.0544, -0.4135]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-21.0009]], device='cuda:0')
value_loss: tensor(11.9455, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor   0%|          | 14/200000 [00:34<151:30:04,  2.73s/it]  0%|          | 15/200000 [00:37<157:21:12,  2.83s/it]tensor([[ 1.4241e+00,  1.4217e-01,  5.5479e-01, -3.2403e-01, -2.6405e-04,
         -1.7635e+00, -1.0855e+00,  4.4658e-01,  1.3541e-01,  8.2028e-01,
          9.0231e-01,  2.0221e+00,  1.2906e+00, -1.2854e+00, -4.7959e-01,
          7.0866e-02, -5.1292e-01, -4.9527e-01, -1.5060e+00, -3.5667e-01]],
       device='cuda:0', grad_fn=<DivBackward0>)
policy_loss: tensor([[20.7353]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(20.7353, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 14

step: 14
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4251,  0.1597,  0.5388, -0.3116,  0.0230, -1.7952, -1.0573,  0.4178,
          0.1520,  0.8453,  0.9108,  2.0051,  1.2691, -1.2658, -0.4560,  0.0438,
         -0.4854, -0.5309, -1.5483, -0.3400]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.425133    0.1597086   0.53883344 -0.31164908  0.02299277 -1.795177
 -1.0573248   0.41780066  0.15199415  0.84532917  0.9107811   2.0050526
  1.2690626  -1.2657743  -0.45597622  0.04383691 -0.48544765 -0.5309054
 -1.5483108  -0.33995998] <class 'numpy.ndarray'>
action2: [ 1.4222025   0.11995054  0.5587755  -0.29706207  0.01847859 -1.7679815
 -1.0303607   0.44394034  0.18202835  0.90746325  0.923114    2.0359755
  1.2643588  -1.216357   -0.50792646  0.05263671 -0.5340224  -0.5333365
 -1.5725224  -0.3413058 ]
action3: [ 1.          0.11995054  0.5587755  -0.29706207  0.01847859 -1.
 -1.          0.44394034  0.18202835  0.90746325  0.923114    1.
  1.         -1.         -0.50792646  0.05263671 -0.5340224  -0.5333365
 -1.         -0.3413058 ]
day: 2 train
Reached the end.
self.asset_memory: [100000, 99996.58942066805, 100104.61946335604]
previous_total_asset:100000
end_total_asset:100104.61946335604
total_reward:104.61946335603716
total_cost:  6.771745331870423
total trades:  20
size: 1
next_state_batch [[8.35574278e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2665, -0.0505,  0.8702, -0.4304, -0.2206, -1.4225, -1.3743,  0.7684,
         -0.0586,  0.5717,  0.7522,  1.9865,  1.5176, -1.4632, -0.7207,  0.4171,
         -0.7794, -0.1599, -1.0561, -0.4139]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[0.0134]], device='cuda:0')
value_loss: tensor(328.7905, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4252,  0.1601,  0.5387, -0.3116,  0.0229, -1.7951, -1.0570,  0.4179,
          0.1519,  0.8453,  0.9108,  2.0053,  1.2688, -1.2655, -0.4560,  0.0438,
         -0.4854, -0.5314, -1.5486, -0.3400]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[17.2337]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(17.2337, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 15
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4225,  0.1764,  0.5260, -0.2983,  0.0466, -1.8277, -1.0292,  0.3888,
          0.1684,  0.8702,  0.9183,  1.9855,  1.2480, -1.2466, -0.4327,  0.0185,
         -0.4584, -0.5656, -1.5883, -0.3225]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4225442   0.17642313  0.5259808  -0.29825267  0.04657525 -1.8276503
 -1.0292253   0.38881934  0.1684052   0.87018365  0.9183409   1.9854654
  1.2479606  -1.246585   -0.4327162   0.01846477 -0.4583544  -0.56556815
 -1.588316   -0.3224952 ] <class 'numpy.ndarray'>
action2: [ 1.4487919   0.13078116  0.5406078  -0.31886032  0.05584814 -1.8060962
 -0.9976066   0.44011635  0.1872573   0.94764036  0.9147508   2.0201542
  1.2537091  -1.2056435  -0.4918224   0.03243421 -0.53341126 -0.6052685
 -1.5904193  -0.32113785]
action3: [ 1.          0.13078116  0.5406078  -0.31886032  0.05584814 -1.
 -0.9976066   0.44011635  0.1872573   0.94764036  0.9147508   1.
  1.         -1.         -0.4918224   0.03243421 -0.53341126 -0.6052685
 -1.         -0.32113785]

step: 15
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4221,  0.1744,  0.5261, -0.2979,  0.0466, -1.8289, -1.0306,  0.3884,
          0.1682,  0.8707,  0.9184,  1.9845,  1.2493, -1.2478, -0.4327,  0.0197,
         -0.4591, -0.5635, -1.5862, -0.3219]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4221408   0.17439203  0.52613467 -0.2978645   0.0465878  -1.8289435
 -1.0305587   0.38843057  0.16815966  0.8706556   0.91843605  1.9845299
  1.249294   -1.2477671  -0.43268594  0.0197311  -0.45910928 -0.56346405
 -1.5862151  -0.3218839 ] <class 'numpy.ndarray'>
action2: [ 1.4289488   0.17914222  0.53403383 -0.33053488  0.0427616  -1.8246586
 -1.0483115   0.37183124  0.14845975  0.87527096  0.89414215  1.9494015
  1.1960831  -1.2430675  -0.45051694  0.00279758 -0.44496548 -0.5704567
 -1.6153166  -0.35909283]
action3: [ 1.          0.17914222  0.53403383 -0.33053488  0.0427616  -1.
 -1.          0.37183124  0.14845975  0.87527096  0.89414215  1.
  1.         -1.         -0.45051694  0.00279758 -0.44496548 -0.5704567
 -1.         -0.35909283]
day: 0 train
actions: [ 10.           1.7914222    5.340338    -3.3053489    0.427616
 -10.         -10.           3.7183123    1.4845974    8.752709
   8.9414215   10.          10.         -10.          -4.5051694
   0.02797577  -4.4496546   -5.704567   -10.          -3.5909283 ]
argsort_actions: [ 5  6 18 13 17 14 16 19  3 15  4  8  1  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 17 14 16 19  3]  buy index:[ 0 12 11 10  9  2  7  1  8  4 15] 
self.sell_num, self.buy_num, self.hold_num: 0 11 9
self.state[HOLDING_IDX~EMB_IDX]: [10.0, 1.7914222478866577, 5.340338230133057, 0, 0.4276160001754761, 0, 0, 3.7183122634887695, 1.4845974445343018, 8.75270938873291, 8.941421508789062, 10.0, 10.0, 0, 0, 0.027975765988230705, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [-10.          -0.3845104   -6.28712797   0.           0.427616
   0.           0.          -5.99526024  -1.54945338  -7.56700325
  -8.99419594 -10.         -10.           0.           0.
  -1.10732979   0.           0.           0.           0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
daybefore_stockprices: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
stockprices_raio: [1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
hold_price_ratio [0.9344104658399371, 0.005227094201613806, 0.0023852136352932336, 0.027809110527307706, 0.0, 0.0007773028563557423, 0.0, 0.0, 0.004938409350013729, 0.0003541139824041443, 0.002469315591531209, 0.0033630133096999343, 0.008932712607351439, 0.009324784736273177, 0.0, 0.0, 8.463362218673167e-06, 0.0, 0.0, 0.0, 0.0]
y_w: [0.9344104658399371, 0.005227094201613806, 0.0023852136352932336, 0.027809110527307706, 0.0, 0.0007773028563557423, 0.0, 0.0, 0.004938409350013729, 0.0003541139824041443, 0.002469315591531209, 0.0033630133096999343, 0.008932712607351439, 0.009324784736273177, 0.0, 0.0, 8.463362218673167e-06, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 0.9999999999999999
end_total_asset [5.22692450e+02 2.38513620e+02 2.78082077e+03 0.00000000e+00
 7.77277621e+01 0.00000000e+00 0.00000000e+00 4.93824902e+02
 3.54102486e+01 2.46923542e+02 3.36290413e+02 8.93242260e+02
 9.32448200e+02 0.00000000e+00 0.00000000e+00 8.46308745e-01
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
begin_total_asset [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
self.daybefore_end_total_asset [1048.73672     294.33586098 6192.09059529    0.            0.
    0.            0.         1298.91834213   73.17181836  468.22373461
  684.5655347  1812.86942    1883.96454       0.            0.
   34.80824235    0.            0.            0.            0.        ]
self.args.diff: None
self.reward:   0%|          | 16/200000 [00:40<156:55:32,  2.82s/it]  0%|          | 17/200000 [00:42<154:59:32,  2.79s/it]-0.010786603989092692
sum end_total_asset(stocks): 6558.740474563741
self.state[0](cash): 93438.01294890136
today cost: -3.525168796961371
size: 1
next_state_batch [[8.35574278e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2667, -0.0503,  0.8700, -0.4303, -0.2203, -1.4230, -1.3741,  0.7681,
         -0.0584,  0.5720,  0.7524,  1.9866,  1.5174, -1.4631, -0.7205,  0.4167,
         -0.7792, -0.1603, -1.0567, -0.4138]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-19.5593]], device='cuda:0')
value_loss: tensor(0.2721, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4223,  0.1757,  0.5260, -0.2980,  0.0465, -1.8283, -1.0297,  0.3887,
          0.1683,  0.8704,  0.9184,  1.9851,  1.2485, -1.2471, -0.4327,  0.0190,
         -0.4587, -0.5647, -1.5874, -0.3222]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[18.2567]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(18.2567, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 16

step: 16
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4168,  0.1925,  0.5162, -0.2840,  0.0706, -1.8606, -1.0011,  0.3600,
          0.1845,  0.8948,  0.9247,  1.9636,  1.2269, -1.2278, -0.4096, -0.0058,
         -0.4313, -0.5995, -1.6265, -0.3044]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4167725   0.19247729  0.51622546 -0.28404653  0.07061108 -1.8606102
 -1.0011028   0.35999158  0.18445897  0.894802    0.924684    1.9636471
  1.226948   -1.2277584  -0.40959495 -0.00581244 -0.43125406 -0.5994713
 -1.6265347  -0.30443218] <class 'numpy.ndarray'>
action2: [ 1.404129    0.20733881  0.5055289  -0.3212649   0.06075626 -1.850239
 -1.0183685   0.35115713  0.1714195   0.90996027  0.95101464  1.917584
  1.1992658  -1.2320246  -0.442754   -0.00430973 -0.41702142 -0.6096794
 -1.6504564  -0.35785705]
action3: [ 1.          0.20733881  0.5055289  -0.3212649   0.06075626 -1.
 -1.          0.35115713  0.1714195   0.90996027  0.95101464  1.
  1.         -1.         -0.442754   -0.00430973 -0.41702142 -0.6096794
 -1.         -0.35785705]
day: 1 train
actions: [ 10.           2.073388     5.0552893   -3.2126489    0.6075626
 -10.         -10.           3.5115714    1.714195     9.099603
   9.510146    10.          10.         -10.          -4.42754
  -0.04309734  -4.170214    -6.096794   -10.          -3.5785704 ]
argsort_actions: [ 5  6 18 13 17 14 16 19  3 15  4  8  1  7  2  9 10 11 12  0]
sell index:[ 5  6 18 13 17 14 16 19  3 15]  buy index:[ 0 12 11 10  9  2  7  1  8  4] 
self.sell_num, self.buy_num, self.hold_num: 1 10 9
self.state[HOLDING_IDX~EMB_IDX]: [20.0, 3.864810347557068, 10.395627498626709, 0, 1.0351786017417908, 0, 0, 7.229883670806885, 3.1987924575805664, 17.852312088012695, 18.45156764984131, 20.0, 20.0, 0, 0, 0.0, 0, 0, 0, 0]
diff_previousday_state[HOLDING_IDX~EMB_IDX]: [10.          2.0733881   5.05528927  0.          0.6075626   0.
  0.          3.51157141  1.71419501  9.0996027   9.51014614 10.
 10.          0.          0.         -0.02797577  0.          0.
  0.          0.        ]
self.state[TARGET_IDX:PRICEDIFF~IDX]: [52.436836, 135.268829, 532.539978, 124.648239, 183.139999, 24.243172, 64.967117, 133.722, 24.116873, 28.690685, 38.167938, 90.643471, 94.198227, 88.973793, 30.700506, 30.659801, 115.387878, 93.627548, 69.499153, 70.641235]
daybefore_stockprices: [52.269245, 133.142044, 520.719971, 122.81459, 181.770004, 24.214939, 63.970062, 132.808884, 23.851751, 28.211098, 37.610397, 89.324226, 93.24482, 88.680862, 29.549698, 30.251495, 113.232193, 92.87384, 68.830414, 68.946892]
stockprices_raio: [1, 1.0032063022911466, 1.0159738046383004, 1.0226993540833487, 1.0149302212383724, 1.007536969631139, 1.0011659331456504, 1.0155862753423626, 1.006875413545377, 1.0111154103528919, 1.0169999409452266, 1.0148241189796534, 1.0147691735946305, 1.0102247717353092, 1.0033032042471577, 1.0389448311789853, 1.0134970519638782, 1.019037739558749, 1.0081153961115423, 1.009715748622404, 1.0245746102666962]
hold_price_ratio [0.8675860715969058, 0.010477058364007875, 0.005222744813146144, 0.05530645395499145, 0.0, 0.0018939625283043852, 0.0, 0.0, 0.009658441679046984, 0.0007706903985350758, 0.005116915869050578, 0.007035660206801403, 0.018110874118782747, 0.01882112647042744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
y_w: [0.8675860715969058, 0.01051065098024487, 0.005306171918467037, 0.05656187473641022, 0.0, 0.0019082372663627304, 0.0, 0.0, 0.009724847459794338, 0.000779256938569827, 0.00520390313664613, 0.007139957670807441, 0.01837835676259355, 0.019013568192388947, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
sum(y_w): 1.0021128966591908
end_total_asset [1048.73672     522.78837002 5536.08723941    0.          189.58260809
    0.            0.          966.79450423   77.14487145  512.19506264
  704.25829006 1812.86942    1883.96454       0.            0.
    0.            0.            0.            0.            0.        ]
begin_total_asset [5.24368360e+02 2.42323590e+02 2.84394360e+03 0.00000000e+00
 7.83135938e+01 0.00000000e+00 0.00000000e+00 4.97220152e+02
 3.58038480e+01 2.51121228e+02 3.41275622e+02 9.06434710e+02
 9.41982270e+02 0.00000000e+00 0.00000000e+00 8.57731418e-01
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
self.daybefore_end_total_asset [5.22692450e+02 2.38513620e+02 2.78082077e+03 0.00000000e+00
 7.77277621e+01 0.00000000e+00 0.00000000e+00 4.93824902e+02
 3.54102486e+01 2.46923542e+02 3.36290413e+02 8.93242260e+02
 9.32448200e+02 0.00000000e+00 0.00000000e+00 8.46308745e-01
 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]
self.args.diff: None
self.reward: 0.010164095054676
sum end_total_asset(stocks): 13254.421625905085
self.state[0](cash): 86843.97274810678
today cost: 3.2628591509998564
size: 1
next_state_batch [[8.35574278e+04 5.24368360e+01 1.35268829e+02 ... 0.00000000e+00
  0.00000000e+00 0.00000000e+00]]
to_tensor(next_state_batch, volatile=True) torch.Size([1, 269801])
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.2669, -0.0501,  0.8696, -0.4302, -0.2201, -1.4235, -1.3737,  0.7678,
         -0.0582,  0.5724,  0.7526,  1.9867,  1.5172, -1.4629, -0.7202,  0.4163,
         -0.7789, -0.1607, -1.0572, -0.4138]], device='cuda:0',
       grad_fn=<DivBackward0>)
target_q_batch: tensor([[-19.5699]], device='cuda:0')
value_loss: tensor(1.4597, device='cuda:0', grad_fn=<MseLossBackward0>)
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4167,  0.1928,  0.5162, -0.2840,  0.0706, -1.8606, -1.0009,  0.3600,
          0.1844,  0.8948,  0.9247,  1.9637,  1.2268, -1.2276, -0.4096, -0.0058,
         -0.4312, -0.5997, -1.6267, -0.3045]], device='cuda:0',
       grad_fn=<DivBackward0>)
policy_loss: tensor([[17.9116]], device='cuda:0', grad_fn=<NegBackward0>)
policy_loss_mean: tensor(17.9116, device='cuda:0', grad_fn=<MeanBackward0>)
step_end: 17

step: 17
state.shape torch.Size([1, 269801])
normalized_tensor tensor([[ 1.4084,  0.2110,  0.5093, -0.2695,  0.0950, -1.8921, -0.9709,  0.3318,
          0.2004,  0.9186,  0.9294,  1.9411,  1.2040, -1.2073, -0.3867, -0.0307,
         -0.4030, -0.6358, -1.6662, -0.2868]], device='cuda:0',
       grad_fn=<DivBackward0>)
action1: [ 1.4083964   0.21095522  0.50926614 -0.2695328   0.0949834  -1.892059
 -0.9708541   0.33180833  0.20042656  0.9186021   0.92937756  1.941106
  1.2039843  -1.2072845  -0.38672137 -0.03066184 -0.40304622 -0.6357779
 -1.6661972  -0.28677127] <class 'numpy.ndarray'>
action2: [ 1.3516883   0.21065386  0.48970273 -0.3041474   0.0864388  -1.8793023
 -0.97497785  0.31848565  0.2026386   0.93895507  0.98995334  1.8717507
  1.1515311  -1.2417737  -0.45048693 -0.03666191 -0.41283688 -0.64426935
 -1.6749939  -0.3196119 ]
action3: [ 1.          0.21065386  0.48970273 -0.3041474   0.0864388  -1.
 -0.97497785  0.31848565  0.2026386   0.93895507  0.98995334  1.
  1.         -1.         -0.45048693 -0.03666191 -0.41283688 -0.64426935
 -1.         -0.3196119 ]
day: 2 train
